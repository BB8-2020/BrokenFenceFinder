{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from labelbox import Client\n",
    "import requests\n",
    "from getpass import getpass\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "from typing import Dict, Any\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import UpSampling2D\n",
    "from keras import Input\n",
    "from keras_segmentation.models.model_utils import get_segmentation_model\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, Conv3D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_mask(image: np.ndarray,\n",
    "                   tool: Dict[str, Any],\n",
    "                   alpha: float = 0.5) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Overlays a mask onto an image\n",
    "    \n",
    "    Args:\n",
    "        image (np.ndarray): image to overlay mask onto\n",
    "        tool (Dict[str,any]): Dict response from the export\n",
    "        alpha: How much to weight the mask when adding to the image\n",
    "    Returns:\n",
    "        image with a point drawn on it.\n",
    "    \"\"\"\n",
    "    mask = np.array(\n",
    "        Image.open(BytesIO(requests.get(\n",
    "            tool[\"instanceURI\"]).content)))[:, :, :1]\n",
    "    mask = mask.reshape(1080, 1920)\n",
    "    \n",
    "    return image, mask\n",
    "    \n",
    "#     cv2.addWeighted\n",
    "#     weighted = cv2.addWeighted(image, alpha, mask, 1 - alpha, 0)\n",
    "#     image[np.sum(mask, axis=-1) > 0] = weighted[np.sum(mask, axis=-1) > 0]\n",
    "#     return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = ''.join([\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.\",\n",
    "\"eyJ1c2VySWQiOiJja214ZmY4dGp2OTNxMDc1N2s2dzRndzY2Ii\",\n",
    "\"wib3JnYW5pemF0aW9uSWQiOiJja214NWg5Znd0ZzUxMDg0ODdp\",\n",
    "\"NHZxMDE3IiwiYXBpS2V5SWQiOiJja215eG1qNHR5eThsMDc0N2\",\n",
    "\"hrdHp3b2ptIiwiaWF0IjoxNjE3Mjg0ODIxLCJleHAiOjIyNDg0\",\n",
    "\"MzY4MjF9.uJ1wDekRxrYtie31RqpoiM_08tWThlShUZrkqjfCDXI\"])\n",
    "print(API_KEY)\n",
    "client = Client(API_KEY)\n",
    "\n",
    "project = client.get_project(\"ckmx5jeqo9u4007902mbiz6k2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_url = project.export_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exports = requests.get(export_url).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(exports[0])\n",
    "# print(exports[0][\"Label\"][\"objects\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmr = 40\n",
    "print(f'Length:{len(exports)}\\n')\n",
    "# Example image\n",
    "images = []\n",
    "masks = []\n",
    "for nmr in range(len(exports)):\n",
    "    export = next(exports)\n",
    "    image = np.array(\n",
    "        Image.open(BytesIO(requests.get(export[\"Labeled Data\"]).content)))\n",
    "    if export[\"Label\"] != {}:\n",
    "        for tool in export[\"Label\"][\"objects\"]:\n",
    "            # All tools have instanceURI but the car was made with the segmentation tool\n",
    "            imageArr, maskArr = visualize_mask(image, tool)\n",
    "            print(nmr, maskArr.shape)\n",
    "            images.append(imageArr)\n",
    "            masks.append(maskArr)\n",
    "#         print(image.shape)\n",
    "#         image = Image.fromarray(imageArr.astype(np.uint8))\n",
    "#         w, h = image.size\n",
    "#         image.resize((w // 4, h // 4))\n",
    "#         display(image)\n",
    "\n",
    "#         print(maskArr.shape)\n",
    "#         mask = Image.fromarray(maskArr)\n",
    "#         w, h = mask.size\n",
    "#         mask.resize((w // 4, h // 4))\n",
    "#         display(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_height = 320\n",
    "input_width = 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_input = Input(shape=(input_height,input_width , 3 ))\n",
    "\n",
    "conv1 = Conv2D(32, (1, 1), activation='relu', padding='same')(img_input)\n",
    "conv1 = Dropout(0.6)(conv1)\n",
    "conv1 = Conv2D(32, (1, 1), activation='relu', padding='same')(conv1)\n",
    "pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "conv2 = Dropout(0.6)(conv2)\n",
    "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "\n",
    "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "conv3 = Dropout(0.6)(conv3)\n",
    "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "\n",
    "up1 = concatenate([UpSampling2D((2, 2))(conv3), conv2], axis=-1)\n",
    "conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(up1)\n",
    "conv4 = Dropout(0.6)(conv4)\n",
    "conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv4)\n",
    "\n",
    "up2 = concatenate([UpSampling2D((2, 2))(conv4), conv1], axis=-1)\n",
    "conv5 = Conv2D(32, (3, 3), activation='relu', padding='same')(up2)\n",
    "conv5 = Dropout(0.6)(conv5)\n",
    "conv5 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "out = Conv2D( 2, (1, 1) , padding='same')(conv5)\n",
    "\n",
    "model = get_segmentation_model(img_input ,  out ) # this would build the segmentation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 320, 640, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 320, 640, 32) 128         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 320, 640, 32) 0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 320, 640, 32) 1056        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 160, 320, 32) 0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 160, 320, 64) 18496       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 160, 320, 64) 0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 160, 320, 64) 36928       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 80, 160, 64)  0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 80, 160, 128) 73856       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 80, 160, 128) 0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 80, 160, 128) 147584      dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 160, 320, 128 0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 160, 320, 192 0           up_sampling2d_2[0][0]            \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 160, 320, 64) 110656      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 160, 320, 64) 0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 160, 320, 64) 36928       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 320, 640, 64) 0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 320, 640, 96) 0           up_sampling2d_3[0][0]            \n",
      "                                                                 conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 320, 640, 32) 27680       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 320, 640, 32) 0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 320, 640, 32) 9248        dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 320, 640, 2)  66          conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 204800, 2)    0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 204800, 2)    0           reshape_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 462,626\n",
      "Trainable params: 462,626\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▊                                                                                                                                                                                | 3/300 [00:00<00:12, 24.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying training dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300/300 [00:12<00:00, 23.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset verified! \n",
      "Epoch 1/30\n",
      "  6/512 [..............................] - ETA: 47s - loss: 1.2356 - accuracy: 0.7347WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0428s vs `on_train_batch_end` time: 0.0518s). Check your callbacks.\n",
      "512/512 [==============================] - 50s 95ms/step - loss: 0.9615 - accuracy: 0.77070s - loss: 0.9622 - ac\n",
      "Epoch 2/30\n",
      "512/512 [==============================] - 49s 95ms/step - loss: 0.8059 - accuracy: 0.7725\n",
      "Epoch 3/30\n",
      "512/512 [==============================] - 49s 95ms/step - loss: 0.7133 - accuracy: 0.7790\n",
      "Epoch 4/30\n",
      "512/512 [==============================] - 49s 96ms/step - loss: 0.6562 - accuracy: 0.7907\n",
      "Epoch 5/30\n",
      "512/512 [==============================] - 49s 96ms/step - loss: 0.6040 - accuracy: 0.8053\n",
      "Epoch 6/30\n",
      "512/512 [==============================] - 51s 100ms/step - loss: 0.5618 - accuracy: 0.8215\n",
      "Epoch 7/30\n",
      "512/512 [==============================] - 53s 103ms/step - loss: 0.5334 - accuracy: 0.8328\n",
      "Epoch 8/30\n",
      "512/512 [==============================] - 53s 103ms/step - loss: 0.5162 - accuracy: 0.8424\n",
      "Epoch 9/30\n",
      "512/512 [==============================] - 53s 103ms/step - loss: 0.4905 - accuracy: 0.8540\n",
      "Epoch 10/30\n",
      "512/512 [==============================] - 52s 102ms/step - loss: 0.4823 - accuracy: 0.8589\n",
      "Epoch 11/30\n",
      "512/512 [==============================] - 51s 100ms/step - loss: 0.4678 - accuracy: 0.8669\n",
      "Epoch 12/30\n",
      "512/512 [==============================] - 49s 96ms/step - loss: 0.4577 - accuracy: 0.8716\n",
      "Epoch 13/30\n",
      "512/512 [==============================] - 49s 96ms/step - loss: 0.4528 - accuracy: 0.8758\n",
      "Epoch 14/30\n",
      "512/512 [==============================] - 49s 97ms/step - loss: 0.4314 - accuracy: 0.8846\n",
      "Epoch 15/30\n",
      "512/512 [==============================] - 49s 97ms/step - loss: 0.4351 - accuracy: 0.8852\n",
      "Epoch 16/30\n",
      "512/512 [==============================] - 50s 99ms/step - loss: 0.4334 - accuracy: 0.8878\n",
      "Epoch 17/30\n",
      "512/512 [==============================] - 51s 99ms/step - loss: 0.4291 - accuracy: 0.8900\n",
      "Epoch 18/30\n",
      "512/512 [==============================] - 51s 100ms/step - loss: 0.4232 - accuracy: 0.8940\n",
      "Epoch 19/30\n",
      "512/512 [==============================] - 52s 103ms/step - loss: 0.4176 - accuracy: 0.8967\n",
      "Epoch 20/30\n",
      "512/512 [==============================] - 53s 104ms/step - loss: 0.4174 - accuracy: 0.8976\n",
      "Epoch 21/30\n",
      "512/512 [==============================] - 53s 104ms/step - loss: 0.4156 - accuracy: 0.8995\n",
      "Epoch 22/30\n",
      "512/512 [==============================] - 53s 104ms/step - loss: 0.4217 - accuracy: 0.8956\n",
      "Epoch 23/30\n",
      "512/512 [==============================] - 53s 104ms/step - loss: 0.4083 - accuracy: 0.9013\n",
      "Epoch 24/30\n",
      "512/512 [==============================] - 53s 104ms/step - loss: 0.4084 - accuracy: 0.9003\n",
      "Epoch 25/30\n",
      "512/512 [==============================] - 53s 103ms/step - loss: 0.4057 - accuracy: 0.9024\n",
      "Epoch 26/30\n",
      "512/512 [==============================] - 53s 104ms/step - loss: 0.3978 - accuracy: 0.9049\n",
      "Epoch 27/30\n",
      "512/512 [==============================] - 54s 105ms/step - loss: 0.4044 - accuracy: 0.9021\n",
      "Epoch 28/30\n",
      "512/512 [==============================] - 53s 104ms/step - loss: 0.4041 - accuracy: 0.9032\n",
      "Epoch 29/30\n",
      "512/512 [==============================] - 50s 97ms/step - loss: 0.4012 - accuracy: 0.9025\n",
      "Epoch 30/30\n",
      "512/512 [==============================] - 50s 97ms/step - loss: 0.4038 - accuracy: 0.9025\n"
     ]
    }
   ],
   "source": [
    "model.train(\n",
    "    train_images = '../../../images_zip/images/',\n",
    "    train_annotations = '../../../images_zip/masks/', \n",
    "    epochs = 30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.predict_segmentation(\n",
    "    inp=\"test1.png\",\n",
    "    out_fname=\"out1_2.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python38364bit5cdb2531dd3545ea9b3fd1a8a995abfc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
